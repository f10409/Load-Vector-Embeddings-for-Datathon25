{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "834abae4-be82-45ac-bcb9-70281cab781b",
   "metadata": {},
   "source": [
    "# Loading Pre-extracted Vector Embeddings into Pandas DataFrames\n",
    "This notebook demonstrates how to load and work with pre-extracted vector embeddings into pandas DataFrames.<br>\n",
    "Vector embeddings are numerical representations of images that capture semantic meaning in high-dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92297c18-3723-4a8d-92bf-7645bd0da4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data manipulation and numerical computing\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Progress tracking for long-running operations\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Type hints for better code documentation and IDE support\n",
    "from typing import List, Literal, Tuple, Optional\n",
    "\n",
    "# Concurrent processing for improved performance\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56179a6b-f554-4e9f-8ddc-ee32a1c0099c",
   "metadata": {},
   "source": [
    "## Core Functions for Loading Embeddings\n",
    "The following functions handle the loading of pre-extracted vector embeddings from disk into pandas DataFrames.<br>\n",
    "The implementation uses parallel processing to efficiently load multiple embedding files simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ed5b8f-22a2-4eef-8817-18238f400544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_single_embedding(sop: str, dataset_path: str, FM: str) -> Tuple[str, Optional[np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Load a single embedding file from disk.\n",
    "    \n",
    "    This helper function handles the loading of individual .npy files containing \n",
    "    pre-computed vector embeddings. It includes error handling for missing files\n",
    "    and corrupted data.\n",
    "    \n",
    "    Args:\n",
    "        sop (str): SOP (Study/Series/Image) identifier - unique ID for the embedding\n",
    "        dataset_path (str): Base path to the dataset embeddings directory\n",
    "        FM (str): Feature model name (e.g., 'RAD-DINO', 'MedImageInsights')\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[str, Optional[np.ndarray]]: \n",
    "            - First element: the SOP identifier (for tracking)\n",
    "            - Second element: loaded embedding array or None if loading failed\n",
    "    \"\"\"\n",
    "    # Construct the full path to the embedding file\n",
    "    # Format: dataset_path/embds_{FM}/{sop}.npy\n",
    "    embedding_file = os.path.join(dataset_path, f'embds_{FM}', sop + '.npy')\n",
    "    \n",
    "    # Check if the embedding file exists before attempting to load\n",
    "    if not os.path.exists(embedding_file):\n",
    "        print(f\"Warning: Embedding file not found for SOP '{sop}': {embedding_file}\")\n",
    "        return sop, None\n",
    "        \n",
    "    try:\n",
    "        # Load the numpy array from disk\n",
    "        # Embeddings are typically stored as .npy files for efficient loading\n",
    "        embd = np.load(embedding_file)\n",
    "        return sop, embd\n",
    "    except Exception as e:\n",
    "        # Handle any errors during file loading (corruption, permissions, etc.)\n",
    "        print(f\"Error loading embedding for SOP '{sop}': {e}\")\n",
    "        return sop, None\n",
    "\n",
    "def load_embeddings(\n",
    "    SOP: List[str], \n",
    "    dataset: Literal['EmoryCXR','MIMIC','MRKR','EMBED'] = 'EmoryCXR', \n",
    "    FM: Literal['MedImageInsights','RAD-DINO','CheXagent','MedGemma','Mammo-CLIP','BiomedCLIP'] = 'RAD-DINO',\n",
    "    max_workers: Optional[int] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load embeddings for multiple SOPs in parallel and return as a pandas DataFrame.\n",
    "    \n",
    "    This function efficiently loads vector embeddings for a list of identifiers using\n",
    "    parallel processing. The embeddings are loaded from pre-computed .npy files and\n",
    "    organized into a pandas DataFrame for easy manipulation and analysis.\n",
    "    \n",
    "    Args:\n",
    "        SOP (List[str]): List of SOP identifiers to load embeddings for\n",
    "        dataset (Literal): Dataset name - specifies which dataset's embeddings to load\n",
    "            Options: 'EmoryCXR', 'MIMIC', 'MRKR', 'EMBED'\n",
    "        FM (Literal): Feature model name - specifies which embedding model to use\n",
    "            Options: 'MedImageInsights', 'RAD-DINO', 'CheXagent', 'MedGemma', 'Mammo-CLIP'\n",
    "        max_workers (Optional[int]): Maximum number of parallel worker threads\n",
    "            Limited to 4 workers max to prevent system overload. Defaults to 4.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with:\n",
    "            - Rows: Each SOP identifier\n",
    "            - Columns: Embedding dimensions (typically 768, 1024, or 2048 features)\n",
    "            - Index: 'SOP' column containing the identifiers\n",
    "    \n",
    "    Raises:\n",
    "        TypeError: If SOP is not a list\n",
    "        ValueError: If SOP list is empty or invalid dataset/FM specified\n",
    "        RuntimeError: If no embeddings could be loaded successfully\n",
    "    \"\"\"\n",
    "    # Input validation - ensure SOP is a list\n",
    "    if not isinstance(SOP, list):\n",
    "        raise TypeError(\"SOP must be a list of identifiers\")\n",
    "    \n",
    "    # Input validation - ensure SOP list is not empty\n",
    "    if not SOP:\n",
    "        raise ValueError(\"SOP list cannot be empty\")\n",
    "    \n",
    "    # Dataset path mapping - defines where embeddings are stored for each dataset\n",
    "    path_dict = {\n",
    "        'EmoryCXR': '/mnt/NAS3/Embeddings/EmoryCXR/',\n",
    "        'MIMIC': '/mnt/NAS3/Embeddings/MIMIC/',\n",
    "        'MRKR': '/mnt/NAS3/Embeddings/MRKR/',\n",
    "        'EMBED': '/mnt/NAS3/Embeddings/EMBED/'\n",
    "    }\n",
    "    \n",
    "    # Validate dataset parameter\n",
    "    if dataset not in path_dict:\n",
    "        raise ValueError(f\"Dataset '{dataset}' not supported. Available: {list(path_dict.keys())}\")\n",
    "    \n",
    "    # Supported feature models - each produces different embedding dimensions\n",
    "    FMs = ['MedImageInsights','RAD-DINO','CheXagent','MedGemma','Mammo-CLIP','BiomedCLIP']\n",
    "    if FM not in FMs:\n",
    "        raise ValueError(f\"FM '{FM}' not supported. Available: {FMs}\")\n",
    "    \n",
    "    # Get the base path for the selected dataset\n",
    "    dataset_path = path_dict[dataset]\n",
    "    \n",
    "    # Dictionary to store successfully loaded embeddings\n",
    "    embds_dict = {}\n",
    "    \n",
    "    # Parallel loading with thread pool\n",
    "    # Limit to 4 workers maximum to prevent overwhelming the file system\n",
    "    effective_max_workers = min(max_workers, 4) if max_workers is not None else 4\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=effective_max_workers) as executor:\n",
    "        # Submit all loading tasks to the thread pool\n",
    "        future_to_sop = {\n",
    "            executor.submit(_load_single_embedding, sop, dataset_path, FM): sop \n",
    "            for sop in SOP\n",
    "        }\n",
    "        \n",
    "        # Collect results as they complete, with progress tracking\n",
    "        for future in tqdm(as_completed(future_to_sop), \n",
    "                          total=len(SOP), \n",
    "                          desc=f\"Loading {FM} embeddings\"):\n",
    "            sop, embedding = future.result()\n",
    "            \n",
    "            # Only store successfully loaded embeddings\n",
    "            if embedding is not None:\n",
    "                embds_dict[sop] = embedding\n",
    "    \n",
    "    # Ensure at least some embeddings were loaded successfully\n",
    "    if not embds_dict:\n",
    "        raise RuntimeError(\"No embeddings were successfully loaded\")\n",
    "    \n",
    "    # Convert dictionary to DataFrame\n",
    "    # - Keys become column names (SOPs)\n",
    "    # - Values become column data (embedding vectors)\n",
    "    # - Transpose so SOPs become rows instead of columns\n",
    "    # - Reset index to make SOP identifiers a proper column\n",
    "    df = pd.DataFrame(embds_dict).T.reset_index(names=['SOP'])\n",
    "    \n",
    "    print(f\"Successfully loaded {len(embds_dict)} embeddings out of {len(SOP)} requested\")\n",
    "    print(f\"Embedding shape: {df.shape[1]-1}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a2aee7-e1c3-4577-9da7-81f71724b7a3",
   "metadata": {},
   "source": [
    "## Metadata loading\n",
    "**Available Embeddings:**<br>\n",
    "<img src=\"./figs/embeddings.png\" alt=\"login\" width=\"750\"><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b369d1-5c10-41c1-a45f-33513390aff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATASET AND MODEL CONFIGURATION\n",
    "# =============================================================================\n",
    "# This section defines the core configuration for loading embeddings.\n",
    "# Modify these variables to switch between datasets or feature models.\n",
    "\n",
    "# Primary dataset selection\n",
    "DATASET = 'EmoryCXR'  # Current dataset being analyzed\n",
    "                      # Options: 'EmoryCXR', 'MIMIC', 'MRKR', 'EMBED'\n",
    "\n",
    "# Feature model selection\n",
    "FM = 'MedGemma'          # Embedding model to use for analysis\n",
    "                         # Available models:\n",
    "                         # - 'MedImageInsights'\n",
    "                         # - 'RAD-DINO'\n",
    "                         # - 'CheXagent'\n",
    "                         # - 'MedGemma'\n",
    "                         # - 'Mammo-CLIP'\n",
    "                         # - 'BiomedCLIP'\n",
    "\n",
    "# =============================================================================\n",
    "# DATASET-SPECIFIC FILE PATHS\n",
    "# =============================================================================\n",
    "# These paths point to the metadata and embedding availability files.\n",
    "# Each dataset has its own directory structure and naming conventions.\n",
    "\n",
    "# Main metadata file containing clinical and imaging information\n",
    "META_PATH = '/mnt/NAS3/CXR/EmoryCXRv2/TABLES/EmoryCXR_v2_Metadata_08112025.csv'\n",
    "# Dataset alternatives (uncomment and modify DATASET variable above):\n",
    "# MIMIC: '/mnt/NAS3/CXR/MIMIC_CXR/physionet.org/files/mimic-cxr-jpg/2.0.0/mimic-cxr-2.0.0-metadata.csv'\n",
    "# MRKR:  '/mnt/NAS3/MRKR_dataset/MRKR_processed_images_08112025.csv'\n",
    "# EMBED: '/mnt/NAS3/EMBED_dataset/EMBED_metadata.csv'\n",
    "\n",
    "# Embedding availability list - tracks which images have pre-computed embeddings\n",
    "EMBDS_LIST_PATH = '/mnt/NAS3/Embeddings/EmoryCXR/embds_list.csv'\n",
    "# This CSV contains boolean columns for each feature model indicating availability\n",
    "# Dataset alternatives:\n",
    "# MIMIC: '/mnt/NAS3/Embeddings/MIMIC/embds_list.csv'\n",
    "# MRKR:  '/mnt/NAS3/Embeddings/MRKR/embds_list.csv'\n",
    "# EMBED: '/mnt/NAS3/Embeddings/EMBED/embds_list.csv'\n",
    "\n",
    "# =============================================================================\n",
    "# DATASET-SPECIFIC IDENTIFIER COLUMNS\n",
    "# =============================================================================\n",
    "# Different datasets use different column names for image identifiers.\n",
    "# This mapping ensures compatibility across datasets.\n",
    "\n",
    "IMAGE_ID_COLUMN = 'SOP'  \n",
    "# Dataset-specific identifier columns:\n",
    "# EmoryCXR: 'SOP' \n",
    "# MRKR: 'SOP'\n",
    "# MIMIC: 'dicom_id'  \n",
    "# EMBED: 'SOPInstanceUID_anon'  \n",
    "\n",
    "# =============================================================================\n",
    "# QUICK DATASET SWITCHING GUIDE\n",
    "# =============================================================================\n",
    "# To switch datasets, update these three variables:\n",
    "# \n",
    "# For MIMIC-CXR:\n",
    "#   DATASET = 'MIMIC'\n",
    "#   IMAGE_ID_COLUMN = 'dicom_id'\n",
    "#   Update META_PATH and EMBDS_LIST_PATH to MIMIC paths\n",
    "#\n",
    "# For MRKR:\n",
    "#   DATASET = 'MRKR' \n",
    "#   IMAGE_ID_COLUMN = 'SOP'\n",
    "#   Update META_PATH and EMBDS_LIST_PATH to MRKR paths\n",
    "#\n",
    "# For EMBED:\n",
    "#   DATASET = 'EMBED'\n",
    "#   IMAGE_ID_COLUMN = 'SOP'\n",
    "#   Update META_PATH and EMBDS_LIST_PATH to EMBED paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3a2e55-bd33-4aed-8ed7-019239f897e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the main metadata file\n",
    "if DATASET == 'EMBED':\n",
    "    meta = pd.read_parquet(META_PATH)\n",
    "else:\n",
    "    meta = pd.read_csv(META_PATH)\n",
    "\n",
    "# Load the list of available embeddings\n",
    "embds_list = pd.read_csv(EMBDS_LIST_PATH)\n",
    "\n",
    "# Merge metadata with embedding availability\n",
    "meta = meta.merge(embds_list, on=IMAGE_ID_COLUMN, how='inner')\n",
    "\n",
    "# Display the merged metadata\n",
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a8bb97-03c5-4318-adb0-c8636a4621a5",
   "metadata": {},
   "source": [
    "### Availability checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783abc3c-7b82-4d51-a349-5d3c929e1479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter metadata to only include images with embeddings for the selected feature model\n",
    "# The metadata contains boolean columns indicating embedding availability for each model\n",
    "print(f\"Selected feature model: {FM}\")\n",
    "print(f\"Total images in metadata: {len(meta)}\")\n",
    "\n",
    "# Create subset containing only images with embeddings for the selected FM\n",
    "# meta[FM] creates a boolean mask - True where embeddings exist for this model\n",
    "meta_sub = meta[meta[FM]].reset_index(drop=True)\n",
    "\n",
    "print(f\"Images with {FM} embeddings: {len(meta_sub)}\")\n",
    "\n",
    "meta_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fd4c43-cfc8-4abd-adb9-292792ff34c6",
   "metadata": {},
   "source": [
    "## Sample selection\n",
    "\n",
    "Here is just an example. Select samples based on you own tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321b34e4-a00c-42d5-8d79-fbfb908b2d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select samples you want to analyze\n",
    "# For large datasets, working with a subset can speed up development and testing\n",
    "\n",
    "samples = meta_sub.sample(n=10000) # random select for example\n",
    "\n",
    "# Extract the list of SOP identifiers from our sample metadata\n",
    "sop_list = list(samples[IMAGE_ID_COLUMN])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c54b6cc-3aeb-4da0-a08b-be66a701b49e",
   "metadata": {},
   "source": [
    "## Embedding loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7500c0d-b36b-49fb-b435-ffc3238e6203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings using parallel processing\n",
    "# This will create a DataFrame with SOPs as rows and embedding dimensions as columns\n",
    "df = load_embeddings(\n",
    "    SOP=sop_list,           # List of identifiers to load embeddings for\n",
    "    dataset=DATASET,     # Dataset name (matches our metadata)\n",
    "    FM=FM                   # Feature model (matches our filtered selection)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7422e082-d549-4750-b255-c09d29271848",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d462152-bebb-4d95-bcbe-ba4e1cd95cf7",
   "metadata": {},
   "source": [
    "## Example Application: Logistic Regression with Embeddings\n",
    "This section demonstrates how to use the loaded vector embeddings for supervised learning tasks. We'll use logistic regression to classify medical findings based on the embedding features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b0199c-bae6-48d6-a280-f0de6bb86ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16b9291-4376-4540-bf0c-1974938bc82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the finding labels for supervised learning\n",
    "# This file contains binary labels for various medical findings/diagnoses\n",
    "print(\"Loading finding labels...\")\n",
    "label = pd.read_csv('/mnt/NAS3/CXR/EmoryCXRv2/TABLES/EmoryCXR_v2_FindingLabel_10162024.csv')\n",
    "\n",
    "# Step 1: Fill NaN values with 0.0 (assuming not mentioned = negative/absent)\n",
    "label = label.fillna(0.0)\n",
    "print(f\"After filling NaN with 0.0: {label.shape}\")\n",
    "\n",
    "# Step 2: Handle uncertain/unknown labels (coded as -1)\n",
    "# Replace -1 with NaN to mark uncertain cases, then remove them\n",
    "label_before_cleaning = len(label)\n",
    "label = label.replace({-1: np.nan}).dropna()\n",
    "print(f\"After removing uncertain labels (-1): {label.shape}\")\n",
    "print(f\"Removed {label_before_cleaning - len(label)} uncertain cases\")\n",
    "\n",
    "# Show the cleaned label data\n",
    "label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dcbcd5-c5d6-4155-a330-dd6135d3c77f",
   "metadata": {},
   "source": [
    "### Linking Embeddings to Study-Level Identifiers\n",
    "To connect our embeddings with the label data, we need to create a mapping between image-level identifiers (SOPs) and study-level identifiers (Accession Numbers). This is essential because labels are often assigned at the study level while embeddings exist at the image level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d520ffd-674e-404a-abc6-f2a4cc92e943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapping between SOP (image-level) and AccessionNumber (study-level)\n",
    "\n",
    "SOP_ACC_mapping = meta[['AccessionNumber_anon','SOP']].drop_duplicates()\n",
    "df = df.merge(SOP_ACC_mapping, on='SOP')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd39ff04-0d6b-45c0-a827-fa45cb908f34",
   "metadata": {},
   "source": [
    "### Merging Embeddings with Labels\n",
    "Now we'll combine our embedding features with the ground truth labels to create the final dataset for machine learning. This step links the vector representations with the clinical findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc003e2-f37d-4753-a114-7a9a24e288de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(label, on='AccessionNumber_anon')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28349ae8-05fc-4455-a9a0-ed632fe881f0",
   "metadata": {},
   "source": [
    "### Logistic Regression Classification Example\n",
    "Now we'll demonstrate how to use the loaded embeddings for a supervised learning task. We'll build a logistic regression classifier to predict cardiomegaly (enlarged heart) from the embedding features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a657597-05d9-47e0-9143-caaf6f14b1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[i for i in range(1024)]] # ex: 1024 for MedGemma\n",
    "y = df['Cardiomegaly']\n",
    "\n",
    "# Proper train/test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Train on training data only\n",
    "clf = LogisticRegression(\n",
    "    random_state=0,\n",
    "    max_iter=1000,\n",
    "    solver='lbfgs',\n",
    "    class_weight='balanced'  # Handle imbalanced classes\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on both sets for comparison\n",
    "train_accuracy = clf.score(X_train, y_train)\n",
    "test_accuracy = clf.score(X_test, y_test)\n",
    "\n",
    "print('train accuracy:', train_accuracy)\n",
    "print('test accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a088b56-48eb-404e-8f3a-dc4c87b8e2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dae603-1bd5-49f8-8f68-63c973e0d3d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Mammo-CLIP",
   "language": "python",
   "name": "mammo-clip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
